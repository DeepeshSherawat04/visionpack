ğŸ§  What is VisionPack AI?

VisionPack AI is an intelligent computer vision project that can detect, classify, and automate the handling of packaging items like boxes and bottles using AI.
It also collects feedback through WhatsApp (Twilio API) to keep improving its accuracy over time â€” just like a learning system that gets smarter with every correction.

Itâ€™s built with YOLOv8, FastAPI, and Streamlit for a full end-to-end experience â€” from detection to feedback to retraining and dashboard visualization.

ğŸš€ Main Features

ğŸ§© Detects and classifies objects using YOLOv8

âš™ï¸ Runs on a FastAPI backend for easy image uploads and predictions

ğŸ” Simulates automation like sorting on left/right conveyors

ğŸ’¬ Uses WhatsApp feedback (Twilio) for correction and learning

ğŸ“ˆ Retrains automatically to improve accuracy

ğŸ–¥ï¸ Has a Streamlit dashboard to upload and visualize detections

ğŸ› ï¸ Tech Stack

Python 3.11+

YOLOv8 (Ultralytics)

FastAPI â€“ Backend API

OpenCV, NumPy, PIL â€“ Image processing

Twilio API â€“ WhatsApp integration

Streamlit â€“ Interactive dashboard

PyTorch â€“ Model training

ğŸ“ Project Structure
visionpack-ai/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI backend routes
â”‚   â”œâ”€â”€ automation/       # Conveyor simulation logic
â”‚   â”œâ”€â”€ feedback/         # WhatsApp feedback + retraining
â”‚   â”œâ”€â”€ dashboard/        # Streamlit dashboard UI
â”‚   â””â”€â”€ models/, utils/   # Helper scripts
â”‚
â”œâ”€â”€ data/                 # Datasets and feedback logs
â”œâ”€â”€ experiments/          # Trained YOLO models
â”œâ”€â”€ runs/                 # Prediction outputs
â”œâ”€â”€ yolov8n.pt            # Base model
â””â”€â”€ .env                  # Twilio credentials

âš™ï¸ How to Set Up and Run
Step 1: Clone the project
git clone https://github.com/<your-username>/visionpack-ai.git
cd visionpack-ai

Step 2: Create and activate virtual environment
python -m venv venv
venv\Scripts\activate

Step 3: Install dependencies
pip install -r requirements.txt

Step 4: Test YOLOv8 installation
yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'

Step 5: Run the FastAPI backend
uvicorn src.api.main:app --reload --port 8000


Then open ğŸ‘‰ http://127.0.0.1:8000/docs

ğŸ’¬ WhatsApp Feedback Setup

Go to Twilio WhatsApp Sandbox

Join the sandbox by sending your join code (e.g. join is-state) to the Twilio number.

In Sandbox Settings, find â€œWhen a message comes inâ€
and paste your ngrok URL + /feedback endpoint there. Example:

https://your-ngrok-url.ngrok.io/feedback


Now send â€œyesâ€ or â€œnoâ€ to your Twilio WhatsApp number.

âœ… Reply â€œyesâ€ â†’ confirms detection is correct

âŒ Reply â€œnoâ€ â†’ system asks for the correct label

Feedback is saved in data/feedback/log.json.

ğŸ” Retrain the Model with Feedback

To make your AI smarter using real feedback:

python src/feedback/retrain.py


This retrains the YOLO model using the feedback data you collected.

ğŸ“Š Streamlit Dashboard

Run this to open the dashboard:

streamlit run src/dashboard/app.py


You can upload images and see the detected objects visually.

ğŸ’¡ Skills Shown in This Project

Object Detection (YOLOv8)

Machine Learning & Model Tuning

API Development (FastAPI)

AI Automation Simulation

WhatsApp API Integration (Twilio)

Data Handling & Retraining

Streamlit Visualization